{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19184e7-0da8-43c2-a226-d331c3df035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Config, LayoutLMv3Model\n",
    "import json\n",
    "\n",
    "# Initializing a LayoutLMv3 microsoft/layoutlmv3-base style configuration\n",
    "with open(\"/home/luckagianvechio/Documents/Material Estudo TCC/code/layoutlmv3/config_alterations.json\", \"r\") as jeiso:\n",
    "    configuration = LayoutLMv3Config(**json.load(jeiso))\n",
    "\n",
    "# Initializing a model (with random weights) from the microsoft/layoutlmv3-base style configuration\n",
    "model = LayoutLMv3Model(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8bf390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29794, 768, padding_idx=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39e9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmv3_embeddings = model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970f0e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayoutLMv3Model(\n",
       "  (embeddings): LayoutLMv3TextEmbeddings(\n",
       "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (position_embeddings): Embedding(512, 768, padding_idx=0)\n",
       "    (x_position_embeddings): Embedding(1024, 128)\n",
       "    (y_position_embeddings): Embedding(1024, 128)\n",
       "    (h_position_embeddings): Embedding(1024, 128)\n",
       "    (w_position_embeddings): Embedding(1024, 128)\n",
       "  )\n",
       "  (patch_embed): LayoutLMv3PatchEmbeddings(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (encoder): LayoutLMv3Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x LayoutLMv3Layer(\n",
       "        (attention): LayoutLMv3Attention(\n",
       "          (self): LayoutLMv3SelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): LayoutLMv3SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): LayoutLMv3Intermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): LayoutLMv3Output(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
       "    (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
       "    (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef73997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel  # or BertModel, for BERT without pretraining heads\n",
    "\n",
    "bertimbau_model = BertModel.from_pretrained('/home/luckagianvechio/Documents/Material Estudo TCC/code/bertimbau')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac15ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertimbau_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd15e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29794, 768, padding_idx=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertimbau_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fec456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings.word_embeddings = bertimbau_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aca3b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29794, 768, padding_idx=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b12f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ImageProcessor\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
    "image_processor = LayoutLMv3ImageProcessor.from_pretrained(\"microsoft/layoutlmv3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2b60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Tokenizer\n",
    "\n",
    "lmv3_tok = LayoutLMv3Tokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b648615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 14478,   230,  5028,   202,  1423,   171,  3420,   119,   102]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Tinha uma pedra no meio do caminho.', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e72257e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  384,  939, 1437,  326, 1717,  385, 1021,    2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.encode(\n",
    "    text='Oi tudo tres quatro cinco seis sete.',\n",
    "    boxes = [[0,1,2,3], [2,3,4,5], [0,1,2,3], [2,3,4,5], [0,1,2,3], [2,3,4,5], [0,1,2,3]],\n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fff79e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   384,   118,   326, 23259,   326,  1535,  2677, 25357,   740,\n",
       "           179,   876,   842,   354,   278,   242,     4,     2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.encode(\n",
    "    text='Oi tudo tres quatro cinco seis sete.'.split(),\n",
    "    boxes = [[0,1,2,3], [2,3,4,5], [0,1,2,3], [2,3,4,5], [0,1,2,3], [2,3,4,5], [0,1,2,3]],\n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "458fa614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  384,  939, 1437,  326, 1717,  385, 1021, 1437,  326,  910,    2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.encode(\n",
    "    text='Oi tudo tres quatro cinco seis sete.',\n",
    "    boxes = [[k, k+1, k+2, k+3] for k in range(0, 40, 4)],\n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e908c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> O i  t u d o</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.decode([   0,  384,  939, 1437,  326, 1717,  385, 1021,    2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "900288b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> O i  t u d o  t r</s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.decode([   0,  384,  939, 1437,  326, 1717,  385, 1021, 1437,  326,  910,    2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1d63d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Oi tudo tres quatro cinco seis sete.</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.decode([    0,   384,   118,   326, 23259,   326,  1535,  2677, 25357,   740,\n",
    "           179,   876,   842,   354,   278,   242,     4,     2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5d8cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>-- O--i-- t--udo-- t--res-- qu--atro-- c--in--co-- se--is-- set--e--.--</s>--"
     ]
    }
   ],
   "source": [
    "toks=[    0,   384,   118,   326, 23259,   326,  1535,  2677, 25357,   740,\n",
    "           179,   876,   842,   354,   278,   242,     4,     2]\n",
    "\n",
    "for tk in toks:\n",
    "    print(lmv3_tok.decode([tk]), end = \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb550c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> O i  t u d o  t r</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = lmv3_tok.encode(\n",
    "    text='Oi tudo tres quatro cinco seis sete.',\n",
    "    boxes = [[k, k+1, k+2, k+3] for k in range(0, 10, 1)],\n",
    "    return_tensors='pt')\n",
    "lmv3_tok.decode(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b815525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  384,  939, 1437,  326, 1717,  385, 1021, 1437,  326,  910,    2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f24849b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckagianvechio/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/models/layoutlmv3/processing_layoutlmv3.py:195: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3Processor\n",
    "\n",
    "lmv3_processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "lmv3_processor.feature_extractor.apply_ocr = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31794bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import listdir\n",
    "\n",
    "main_path = Path(\"/home/luckagianvechio/Documents/Material Estudo TCC/IIT CDIP/images.a.a/imagesa/a/a\")\n",
    "a_path = Path(\"a/\")\n",
    "a_img_folder_path = [main_path / a_path / Path(pt) for pt in listdir(main_path / a_path)]\n",
    "a_img_path = []\n",
    "for pt in a_img_folder_path:\n",
    "    files = listdir(pt)\n",
    "    for file in files:\n",
    "        if not file.split(\".\")[1] == \"xml\":\n",
    "            a_img_path.append(pt / file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87271927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr_tools import get_ocr_word_box_list, preprocess_image, resize_image, read_image, normalize_bbox\n",
    "\n",
    "image = read_image(a_img_path[0])\n",
    "text_boxes, shape = get_ocr_word_box_list(a_img_path[0])\n",
    "words = [k[\"text\"] for k in text_boxes]\n",
    "boxes = [normalize_bbox(k[\"bbox\"], shape[0], shape[1]) for k in text_boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "353d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = lmv3_processor(\n",
    "    image,\n",
    "    words,\n",
    "    boxes=boxes,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ede27a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'bbox', 'pixel_values'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769271cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[127, 368, 149, 377],\n",
       "        [151, 368, 174, 375],\n",
       "        [ 71, 389,  98, 398],\n",
       "        [ 71, 389,  98, 398],\n",
       "        [100, 389, 110, 396],\n",
       "        [113, 389, 133, 396],\n",
       "        [113, 389, 133, 396],\n",
       "        [113, 389, 133, 396],\n",
       "        [113, 389, 133, 396],\n",
       "        [135, 389, 179, 396],\n",
       "        [181, 389, 192, 396],\n",
       "        [181, 389, 192, 396],\n",
       "        [194, 391, 206, 396],\n",
       "        [208, 389, 221, 396],\n",
       "        [223, 389, 233, 396],\n",
       "        [236, 390, 245, 396],\n",
       "        [247, 388, 275, 397],\n",
       "        [278, 388, 285, 397],\n",
       "        [286, 388, 297, 395],\n",
       "        [ 71, 399, 100, 407],\n",
       "        [102, 400, 116, 407],\n",
       "        [118, 399, 125, 407],\n",
       "        [127, 399, 152, 407],\n",
       "        [154, 399, 171, 407],\n",
       "        [173, 399, 176, 407],\n",
       "        [178, 401, 194, 409],\n",
       "        [196, 399, 202, 407],\n",
       "        [203, 399, 212, 407],\n",
       "        [214, 399, 238, 407],\n",
       "        [240, 399, 253, 406],\n",
       "        [255, 399, 261, 406],\n",
       "        [262, 399, 271, 406],\n",
       "        [273, 399, 301, 406],\n",
       "        [ 71, 410, 103, 419],\n",
       "        [ 71, 410, 103, 419],\n",
       "        [106, 410, 114, 418],\n",
       "        [106, 410, 114, 418],\n",
       "        [117, 410, 134, 419],\n",
       "        [117, 410, 134, 419],\n",
       "        [344, 557, 348, 561],\n",
       "        [344, 563, 348, 567],\n",
       "        [344, 569, 348, 573],\n",
       "        [344, 575, 348, 579],\n",
       "        [343, 581, 348, 586],\n",
       "        [343, 593, 348, 598],\n",
       "        [343, 600, 348, 604],\n",
       "        [343, 605, 348, 610],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['bbox'][0][-350:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33d68cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3TextEmbeddings(\n",
      "  (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
      "  (x_position_embeddings): Embedding(1024, 128)\n",
      "  (y_position_embeddings): Embedding(1024, 128)\n",
      "  (h_position_embeddings): Embedding(1024, 128)\n",
      "  (w_position_embeddings): Embedding(1024, 128)\n",
      ") tensor([[    0,  7330, 15318,   109,   242,  2841,  1046,    17,    27,   262,\n",
      "         24303, 37317,     4,  4979, 13895,   565, 14718, 10566,    35,   719,\n",
      "           753,     6,  7528, 33355, 10566,    35,  5457,   759,   733,     6,\n",
      "          7528, 40950,  1499,  4177, 10486,    35, 30627,     6,   886, 40950,\n",
      "          1499, 11185,   337,  1872,    44,   711,   713, 11020, 20026, 13133,\n",
      "             9,   143,  1203,     6, 11566,     6, 15155,  1120,    50, 11267,\n",
      "          2332,    14, 26238,  5504, 14407,    50, 22589, 14281,    11,    10,\n",
      "          3271,  7097,  2259,     4,  1909,   352,  7097,     7, 41684,  1171,\n",
      "          6185, 30792,     6,  2380,     9,  3413,     8,  7619,   990, 20515,\n",
      "          1203, 15659,     4,    20, 11020, 30540,  8127,  1480,  7205,   975,\n",
      "             7,     5,   511,    35,  2055, 26855,  1025,     5, 11457,    14,\n",
      "            32, 10059,     7,  1331, 14407,     4, 11548,  9501,  1734,   341,\n",
      "             7,  4240, 14407, 11548, 25675,    29,    41, 10718, 14450,    83,\n",
      "           922, 13562,  5846,  1734,  5505,  7258, 26855,    15,  1038, 12142,\n",
      "             7,    41, 22233,  6418,  2055, 40989,  9390,   137,     5,  2375,\n",
      "          1248,     9,    42, 22474, 39877,    50,     7,   143, 14573,  1385,\n",
      "             9,    41,  2210,  1355, 38906, 43650,     8,  1076,   876,  5410,\n",
      "           328, 20170,  3553,   337,   122,  5152,     8,    32,  9986,    30,\n",
      "            42, 11020,   531,    28,  2928,   624,   132,   107,     9,     5,\n",
      "          2375,  1248,     9,     5, 11020,    36, 21206,   733,     6,  6193,\n",
      "           322,   885,   290,   290,  1021,    10,   787,   234,  1021,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprocessed)\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/models/layoutlmv3/modeling_layoutlmv3.py:896\u001b[0m, in \u001b[0;36mLayoutLMv3Model.forward\u001b[0;34m(self, input_ids, bbox, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    894\u001b[0m         bbox \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mtuple\u001b[39m(\u001b[39mlist\u001b[39m(input_shape) \u001b[39m+\u001b[39m [\u001b[39m4\u001b[39m]), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    895\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings, input_ids)\n\u001b[0;32m--> 896\u001b[0m     embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m    897\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    898\u001b[0m         bbox\u001b[39m=\u001b[39;49mbbox,\n\u001b[1;32m    899\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    900\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    901\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    902\u001b[0m     )\n\u001b[1;32m    904\u001b[0m final_bbox \u001b[39m=\u001b[39m final_position_ids \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    905\u001b[0m patch_height \u001b[39m=\u001b[39m patch_width \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/models/layoutlmv3/modeling_layoutlmv3.py:336\u001b[0m, in \u001b[0;36mLayoutLMv3TextEmbeddings.forward\u001b[0;34m(self, input_ids, bbox, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    333\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[1;32m    337\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    339\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model(**processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a590bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.embeddings.word_embeddings = lmv3_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089e58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Altempt doe em age’ 7} RJ. RE ERT Alert Date: December 19, 1997 Effective Date: = November 21, 1997 Restriction Geography: Compton, California Restriction Detalts ‘This ordinance prohibits placement of any sign, poster, placard or graphic display that advertises cigarettes or alcoholic beverages in a publicly visible location. Publicly visible tocation includes outdoor billboards, sides of buildings and freestanding signboards. The ordinance DOES NOT APPLY to the following: + Signs inside the premises that are licensed to sell cigarettes. « Commercial vehicles used to transport cigarettes «Signs an Metropolitan Transit Aulhorily vehicles ¢ Signs on property adjacent to an interstate highway + Contracts executed before the effective date of this ordnance or to any renewal term of an existing contract Cigarette and alcoho! advertisements thal now exist and are prohibited by this ordinance must be removed within 2 years of the effective date of the ordinance (November 21, 1999). w 8 8 o a @ N o</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_tok.decode(processed['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf5e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    1, -100,    1, -100,    1,    1, -100, -100,    1, -100,    1,\n",
       "         -100,    1,    1, -100,    1,    1, -100,    1,    1, -100,    1,    1,\n",
       "            1, -100,    1,    1,    1, -100,    1,    1, -100,    1, -100, -100,\n",
       "            1, -100,    1,    1, -100,    1, -100, -100,    1,    1, -100,    1,\n",
       "            1,    1,    1,    1,    1, -100,    1, -100,    1, -100,    1,    1,\n",
       "            1,    1,    1, -100,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1, -100,    1, -100,    1,    1, -100,    1,    1,    1, -100,    1,\n",
       "            1,    1,    1,    1, -100, -100,    1, -100, -100,    1,    1,    1,\n",
       "            1,    1, -100, -100,    1,    1,    1, -100,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1, -100,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1, -100, -100,    1,    1,    1,    1, -100, -100,\n",
       "         -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1, -100,    1,    1,\n",
       "         -100, -100, -100,    1,    1, -100,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1, -100,    1, -100,    1, -100,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmv3_processor(\n",
    "    image,\n",
    "    words,\n",
    "    word_labels = [1 for k in range(len(words))],\n",
    "    boxes=boxes,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f396ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_processor import tokenize_with_bbox, pad_tokenized\n",
    "\n",
    "new_processed = tokenize_with_bbox(\n",
    "    words=words,\n",
    "    bboxs=boxes,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "padded_new_processed = pad_tokenized(new_processed, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertimbau_embeddings = bertimbau_model.embeddings.word_embeddings\n",
    "model.embeddings.word_embeddings = bertimbau_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403fd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "processed_new_tokenizer = processed.copy()\n",
    "processed_new_tokenizer[\"input_ids\"][0] = Tensor(padded_new_processed[\"input_ids\"])\n",
    "processed_new_tokenizer[\"bbox\"][0] = Tensor(padded_new_processed[\"bbox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f3311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3TextEmbeddings(\n",
      "  (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (position_embeddings): Embedding(512, 768, padding_idx=0)\n",
      "  (x_position_embeddings): Embedding(1024, 128)\n",
      "  (y_position_embeddings): Embedding(1024, 128)\n",
      "  (h_position_embeddings): Embedding(1024, 128)\n",
      "  (w_position_embeddings): Embedding(1024, 128)\n",
      ") tensor([[  476,  2097,  5131,   171, 22279,   173,  9174, 22361,   977,   197,\n",
      "         19647,   119,   257, 22309,   192, 20257,  1043, 22282, 22286,  1292,\n",
      "           185,   131,  4534,   210,   604,   275,   117,  6827,   192, 14782,\n",
      "          5965,  1086,  1292,   185,   131,   134,  4424,   210,   604,  2250,\n",
      "           117,  6827,  4151,  9581,  1131,  1992,  4009,  9558,   131,  2174,\n",
      "           897,   117, 19921,  4151,  9581,  1131,   540,   477,  1355,  8586,\n",
      "         16989,  4189,   387,  1710,   258,  4095,  5257, 22281,  1269,  2812,\n",
      "           265,   586,   360, 22326,  1493,   117, 13608,   140,   117,  9109,\n",
      "         22284,   438,   416,  1814,   156,  4267, 12893, 12230,   352, 11760,\n",
      "          4530,   143, 14883,   823,  6060, 22281,   438, 15460, 15203,   156,\n",
      "          5294,  5042,  4119,   238,   123,  1336,  2021,  1003, 20900,   817,\n",
      "           352,   484,   119, 10927,  2021,  1003, 20900,  7384,  1131,   868,\n",
      "          1111,   291, 22286,   243,   141,  3425, 22290,  4201, 22281,   117,\n",
      "           898,  1111,   586, 10187,  6845,  4403,  1961,   958,  1009, 10773,\n",
      "           833,  1493,  4201, 22281,   119,  1389,  4189,   387,  1710, 15040,\n",
      "          3341, 20660, 22321, 12127, 22310, 22327, 22350,   374,  1621,  3370,\n",
      "          7127,   446,   131,   116, 13463,   255,   601,   878,  1621, 11050,\n",
      "          1932, 12230,   352, 12346,  4073,  1451, 22284,   374, 13970, 22290,\n",
      "         14883,   823,  6060, 22281,   119,   208,   761,   580,   550,   873,\n",
      "          4095, 20929,   727,   430,   374,  4636, 22286, 14883,   823,  6060,\n",
      "         22281,   208, 13463,   255,   360, 15509,  4175, 22285,  4339,   284,\n",
      "          2116, 22290,   914,  6417,   873,  4095, 20929,   100, 13463,   255,\n",
      "          3185,  2671, 20057, 22326, 12756,  2853,   374,   360,   558,  8849,\n",
      "           185,  4163,  2719,  4473,   116, 10389,  5965, 22281,  2246,  3640,\n",
      "          5294,   512, 22279,  1621,  1691, 18273,  6758,   180,   185,   586,\n",
      "         12230,   145,  4189, 20313,   289,   438,   374,   360, 22326,  5302,\n",
      "         22279,  7761,   370, 22287,   586,   360, 21877,   833,   598,  5965,\n",
      "           187,   945, 15738, 22279,  1961, 15460,   268,   106, 11760,  4530,\n",
      "           210,   265, 22281, 12230,   162,   202, 22343,  7288,  1961, 12346,\n",
      "           258,  4095,  5257,   430, 11100, 12230,   145,  4189,   387,  1710,\n",
      "          3270, 22286,  5294,  2873, 20384, 10125,   147,   245,  4759, 22279,\n",
      "          6425,   586,  1621,  1691, 18273,  6758,   180,   185,   586,  1621,\n",
      "          4189,   387,  1710,   113,  4424,   210,   604,  2250,   117,  6051,\n",
      "           114,   119,  2702,  1015,  1015,   146,   123,   137,   248,   146,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckagianvechio/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/modeling_utils.py:993: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.1568, -0.2598, -0.2371,  ..., -1.0681,  0.5948,  0.8614],\n",
       "         [-0.0803, -2.0187, -1.3858,  ...,  0.1783, -1.8378,  1.4976],\n",
       "         [-0.3958,  0.6073, -0.3292,  ..., -1.5268, -0.1432, -0.4828],\n",
       "         ...,\n",
       "         [ 1.0745,  1.1467, -0.3228,  ..., -0.8103,  0.1111,  0.6372],\n",
       "         [ 1.1398,  1.4831,  0.6356,  ..., -0.8528, -0.7138,  0.1530],\n",
       "         [ 0.6453,  0.7477,  1.2914,  ..., -0.9224,  0.0406,  0.0370]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**processed_new_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193e862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([512]) torch.Size([512])\n",
      "torch.Size([512, 4]) torch.Size([512, 4])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for key in processed.keys():\n",
    "    print(processed_new_tokenizer[key].squeeze().shape, processed[key].squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43971cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Altempt doe em age ’ 7 } RJ. RE ERT Alert Date : December 19, 1997 Effective Date : = November 21, 1997 Restriction Geography : Compton, California Restriction Detalts ‘ This ordinance prohibits placement of any sign, poster, placard or graphic display that advertises cigarettes or alcoholic beverages in a publicly visible location. Publicly visible tocation includes outdoor billboards, sides of buildings and freestanding signboards. The ordinance DOES NOT APPLY to the following : + Signs inside the premises that are licensed to sell cigarettes. « Commercial vehicles used to transport cigarettes « Signs an Metropolitan Transit Aulhorily vehicles [UNK] Signs on property adjacent to an interstate highway + Contracts executed before the effective date of this ordnance or to any renewal term of an existing contract Cigarette and alcoho! advertisements thal now exist and are prohibited by this ordinance must be removed within 2 years of the effective date of the ordinance ( November 21, 1999 ). w 8 8 o a @ N o [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(processed_new_tokenizer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579f52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  476,  2097,  5131,   171, 22279,   173,  9174, 22361,   977,   197,\n",
       "         19647,   119,   257, 22309,   192, 20257,  1043, 22282, 22286,  1292,\n",
       "           185,   131,  4534,   210,   604,   275,   117,  6827,   192, 14782,\n",
       "          5965,  1086,  1292,   185,   131,   134,  4424,   210,   604,  2250,\n",
       "           117,  6827,  4151,  9581,  1131,  1992,  4009,  9558,   131,  2174,\n",
       "           897,   117, 19921,  4151,  9581,  1131,   540,   477,  1355,  8586,\n",
       "         16989,  4189,   387,  1710,   258,  4095,  5257, 22281,  1269,  2812,\n",
       "           265,   586,   360, 22326,  1493,   117, 13608,   140,   117,  9109,\n",
       "         22284,   438,   416,  1814,   156,  4267, 12893, 12230,   352, 11760,\n",
       "          4530,   143, 14883,   823,  6060, 22281,   438, 15460, 15203,   156,\n",
       "          5294,  5042,  4119,   238,   123,  1336,  2021,  1003, 20900,   817,\n",
       "           352,   484,   119, 10927,  2021,  1003, 20900,  7384,  1131,   868,\n",
       "          1111,   291, 22286,   243,   141,  3425, 22290,  4201, 22281,   117,\n",
       "           898,  1111,   586, 10187,  6845,  4403,  1961,   958,  1009, 10773,\n",
       "           833,  1493,  4201, 22281,   119,  1389,  4189,   387,  1710, 15040,\n",
       "          3341, 20660, 22321, 12127, 22310, 22327, 22350,   374,  1621,  3370,\n",
       "          7127,   446,   131,   116, 13463,   255,   601,   878,  1621, 11050,\n",
       "          1932, 12230,   352, 12346,  4073,  1451, 22284,   374, 13970, 22290,\n",
       "         14883,   823,  6060, 22281,   119,   208,   761,   580,   550,   873,\n",
       "          4095, 20929,   727,   430,   374,  4636, 22286, 14883,   823,  6060,\n",
       "         22281,   208, 13463,   255,   360, 15509,  4175, 22285,  4339,   284,\n",
       "          2116, 22290,   914,  6417,   873,  4095, 20929,   100, 13463,   255,\n",
       "          3185,  2671, 20057, 22326, 12756,  2853,   374,   360,   558,  8849,\n",
       "           185,  4163,  2719,  4473,   116, 10389,  5965, 22281,  2246,  3640,\n",
       "          5294,   512, 22279,  1621,  1691, 18273,  6758,   180,   185,   586,\n",
       "         12230,   145,  4189, 20313,   289,   438,   374,   360, 22326,  5302,\n",
       "         22279,  7761,   370, 22287,   586,   360, 21877,   833,   598,  5965,\n",
       "           187,   945, 15738, 22279,  1961, 15460,   268,   106, 11760,  4530,\n",
       "           210,   265, 22281, 12230,   162,   202, 22343,  7288,  1961, 12346,\n",
       "           258,  4095,  5257,   430, 11100, 12230,   145,  4189,   387,  1710,\n",
       "          3270, 22286,  5294,  2873, 20384, 10125,   147,   245,  4759, 22279,\n",
       "          6425,   586,  1621,  1691, 18273,  6758,   180,   185,   586,  1621,\n",
       "          4189,   387,  1710,   113,  4424,   210,   604,  2250,   117,  6051,\n",
       "           114,   119,  2702,  1015,  1015,   146,   123,   137,   248,   146,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_new_tokenizer['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddd77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22361)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(processed_new_tokenizer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertimbau_embeddings = bertimbau_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.1749e-02, -7.5483e-03, -5.3265e-02,  7.9719e-03, -2.2911e-02,\n",
       "        -3.7143e-02,  4.8871e-03, -1.9706e-02, -2.4039e-04, -4.5227e-02,\n",
       "        -1.8988e-02,  1.3754e-02, -2.5060e-02, -3.9911e-02, -3.8198e-02,\n",
       "         7.9675e-03,  1.0591e-02, -1.5516e-02, -1.9410e-02, -9.3070e-02,\n",
       "         3.8822e-02,  2.4400e-02, -4.6231e-02, -3.9224e-02, -4.9267e-02,\n",
       "        -5.1528e-02,  2.4972e-03, -4.0830e-02, -1.8358e-02, -3.7181e-02,\n",
       "        -3.4045e-02, -2.0300e-02,  4.2643e-02, -4.8424e-02,  3.0170e-02,\n",
       "         3.0366e-02, -2.8620e-02, -6.3595e-02,  1.1377e-03, -4.3281e-02,\n",
       "         2.6231e-02, -4.0770e-02,  6.7154e-02,  2.0910e-02,  4.2354e-02,\n",
       "        -2.5098e-02, -2.5217e-02, -6.4154e-02,  1.2690e-02, -1.4113e-02,\n",
       "         3.6339e-02, -1.0496e-02, -6.5917e-02,  5.9714e-02,  3.0761e-02,\n",
       "        -2.3547e-01, -2.7711e-02,  1.0110e-02, -8.5547e-03, -1.9117e-02,\n",
       "        -3.2750e-02, -1.3825e-02,  6.4325e-03, -1.0901e-02, -3.0468e-02,\n",
       "        -1.7198e-02, -1.7289e-02, -1.8503e-02, -7.0999e-02, -6.5664e-04,\n",
       "        -5.2223e-03, -5.9639e-03, -3.4913e-02, -2.4328e-02, -8.4378e-03,\n",
       "        -2.3980e-02,  2.4152e-02,  1.5849e-02, -6.2998e-02, -6.2424e-02,\n",
       "         1.6992e-02, -7.8205e-03, -1.1096e-02, -1.0771e-02,  1.2837e-02,\n",
       "        -3.6279e-04,  4.5472e-03,  2.1502e-02, -1.8636e-02, -6.5587e-02,\n",
       "        -2.8200e-02, -2.1118e-02, -6.1105e-03, -7.6882e-03, -5.7048e-03,\n",
       "        -9.6802e-03, -2.6758e-02,  3.9273e-03,  3.1897e-02, -9.4493e-03,\n",
       "         3.5047e-03,  1.3975e-02, -6.7024e-03,  2.1145e-02, -2.7218e-02,\n",
       "        -1.5412e-03, -3.0643e-02,  1.2617e-02, -2.9468e-02, -6.7714e-02,\n",
       "         9.0411e-03,  1.4386e-02,  2.0764e-02, -7.3715e-02, -5.1107e-03,\n",
       "         2.8083e-02,  1.9859e-02, -2.8158e-02,  2.1405e-02, -3.3134e-02,\n",
       "         1.4800e-02,  3.0569e-02,  1.5227e-02, -2.3225e-02,  1.3708e-02,\n",
       "        -1.1354e-02,  1.1737e-02, -2.1285e-03, -3.1566e-02,  3.4387e-02,\n",
       "         1.9358e-02, -2.7644e-02,  5.9637e-02,  2.1256e-02,  4.2979e-03,\n",
       "        -3.1597e-02,  3.4826e-02,  3.9864e-02, -1.5402e-02,  1.9016e-03,\n",
       "         1.8147e-02, -3.6467e-02,  1.7832e-02, -1.8035e-02, -4.3214e-02,\n",
       "        -5.0317e-02,  1.6767e-02, -3.0841e-02, -2.7704e-02,  1.2278e-03,\n",
       "         4.3789e-04,  1.1405e-02,  1.7167e-02,  2.8788e-02, -1.9017e-02,\n",
       "        -6.3313e-02,  6.8315e-03, -2.1721e-03,  1.8944e-02, -8.9221e-02,\n",
       "         1.3960e-02,  1.4154e-02, -1.1464e-03,  3.3675e-02, -1.7179e-02,\n",
       "         3.2875e-02, -3.6704e-02, -4.2526e-02,  3.3656e-02, -1.1025e-02,\n",
       "        -3.3418e-02, -3.3432e-02, -1.9029e-02, -6.2444e-02, -2.7209e-02,\n",
       "        -3.5818e-02, -4.5948e-02, -6.6613e-02, -4.7921e-03, -2.9648e-02,\n",
       "         8.9080e-03, -2.4272e-02, -3.5325e-02, -3.8981e-04, -4.7429e-02,\n",
       "        -3.6652e-02,  3.1727e-02, -7.9225e-02, -2.3019e-02, -2.0661e-02,\n",
       "         2.1370e-02,  1.4651e-02, -5.9871e-02, -6.6642e-04, -3.1684e-02,\n",
       "         3.3302e-03, -6.6649e-02, -1.4030e-02, -2.2499e-02, -1.1882e-02,\n",
       "        -4.3886e-02, -7.5293e-02,  1.8117e-02,  2.4667e-02, -1.1231e-02,\n",
       "        -1.2026e-02, -7.7304e-02, -1.6659e-01, -1.3450e-02,  4.2718e-03,\n",
       "         2.7367e-02, -2.2210e-02, -6.5988e-03, -3.4360e-03,  1.5878e-03,\n",
       "         9.5259e-03, -4.7972e-02,  2.9621e-02, -2.5345e-02,  3.7647e-02,\n",
       "         3.8032e-02, -9.6722e-03, -1.4219e-02, -2.7722e-02, -2.0211e-03,\n",
       "         3.2985e-02, -8.6760e-02, -9.3843e-02,  3.3849e-02, -6.6766e-02,\n",
       "        -6.0603e-03,  1.7961e-02, -8.5379e-03, -3.6024e-02, -4.7188e-03,\n",
       "        -3.7499e-02, -1.7614e-02,  6.4527e-03,  2.9605e-02,  1.2085e-02,\n",
       "        -5.1464e-02, -1.7382e-02,  9.0956e-03, -2.5116e-02,  4.7047e-03,\n",
       "        -2.3686e-02, -1.9684e-02,  1.5527e-03, -4.5385e-03, -2.1416e-02,\n",
       "        -4.3516e-02,  1.3040e-02, -2.5576e-02,  4.1095e-02,  3.1772e-03,\n",
       "        -1.3230e-02, -8.2253e-02, -3.5562e-02, -1.3127e-02,  4.1840e-03,\n",
       "        -4.6017e-02, -3.3078e-02, -4.3613e-02, -2.1628e-02, -6.9404e-03,\n",
       "         2.6659e-02, -3.7091e-02,  1.9637e-02, -1.3212e-02,  1.2943e-03,\n",
       "        -2.1412e-02,  4.5748e-03,  1.4821e-04, -5.3327e-02, -5.5121e-03,\n",
       "        -4.1263e-02,  8.7082e-03,  8.1080e-03, -3.1293e-02, -2.8201e-02,\n",
       "        -9.4145e-03, -4.9089e-02,  5.4054e-02, -1.6873e-02, -1.9937e-02,\n",
       "         1.4984e-02, -2.5823e-02, -2.1321e-02, -1.5649e-02, -2.0591e-02,\n",
       "        -3.2742e-03,  1.6219e-02, -2.4602e-02, -2.7882e-02, -4.5476e-02,\n",
       "         1.1461e-02, -2.2570e-02, -1.7714e-02,  1.2759e-02, -1.7683e-02,\n",
       "        -2.6758e-02, -4.7031e-02,  2.2533e-02, -4.3506e-02, -1.0325e-02,\n",
       "         5.0047e-03, -1.4388e-02,  1.5145e-02,  2.4322e-02, -1.6281e-02,\n",
       "        -4.6033e-02, -1.8592e-02,  1.3169e-02, -1.4798e-02, -1.5121e-02,\n",
       "         5.6794e-02, -2.0037e-02,  1.1252e-02, -3.8299e-02, -1.9330e-02,\n",
       "        -1.4411e-02, -1.5699e-01,  2.1475e-02, -1.5263e-02, -6.1524e-02,\n",
       "        -5.6305e-02, -8.8263e-03,  2.5027e-02, -3.7487e-02, -7.7541e-03,\n",
       "         1.7738e-02, -3.3434e-02,  5.4532e-02,  1.6960e-02, -1.2936e-02,\n",
       "        -2.8631e-02, -4.3902e-03, -1.1441e-03, -7.3436e-02,  6.5825e-04,\n",
       "         6.3221e-03, -3.6373e-02,  1.2191e-02,  2.3276e-02, -1.2381e-02,\n",
       "        -9.4821e-03, -7.6537e-03,  6.5987e-02,  2.3588e-02, -4.5158e-02,\n",
       "        -4.7172e-02, -2.0777e-02, -2.3284e-02,  3.7089e-02, -1.1350e-02,\n",
       "        -5.4941e-02,  3.5403e-02,  4.8577e-02, -5.9267e-02, -2.9388e-02,\n",
       "         3.5735e-02,  2.1625e-02,  6.9465e-03,  4.8781e-03, -2.3268e-02,\n",
       "        -1.5927e-02, -2.9773e-02, -2.5183e-02, -3.2264e-02, -9.3702e-03,\n",
       "        -3.2298e-02, -2.4503e-02, -5.2840e-02, -3.2025e-02,  6.7577e-03,\n",
       "         2.2054e-02,  2.5338e-02,  3.7163e-02,  4.3011e-02, -4.2356e-02,\n",
       "        -2.3087e-02, -4.0625e-02,  5.8170e-04, -2.5500e-02, -3.5076e-01,\n",
       "        -3.3806e-02,  1.4577e-02, -4.1675e-02,  1.0791e-02,  1.1816e-02,\n",
       "        -7.4602e-02, -2.7650e-03, -3.5590e-02,  6.4131e-03, -3.3214e-02,\n",
       "        -1.3308e-02, -6.8989e-03,  3.0375e-02,  2.9498e-02,  1.5801e-02,\n",
       "        -5.5302e-02,  9.2598e-03,  3.3132e-02,  1.7377e-02,  5.6422e-04,\n",
       "        -4.0456e-02,  2.8443e-02,  3.1622e-02,  2.1931e-02, -2.5544e-02,\n",
       "        -9.2094e-02, -2.7335e-02, -3.4339e-02,  2.6934e-02, -2.3717e-02,\n",
       "        -1.1496e-02, -3.2567e-03, -1.8355e-02, -1.1611e-02, -1.6193e-02,\n",
       "        -3.8749e-02, -4.1421e-03,  1.0621e-03,  2.6778e-02, -5.5501e-02,\n",
       "         2.2107e-02,  1.3573e-03,  3.7304e-02, -2.0586e-02,  3.2736e-02,\n",
       "        -2.2987e-02, -2.7318e-02, -6.3220e-03, -3.7190e-02,  1.8417e-02,\n",
       "        -1.1076e-03, -2.8992e-01, -2.5252e-02, -2.0844e-02, -1.8569e-01,\n",
       "         1.8385e-02, -3.7748e-03,  2.4878e-02,  2.8460e-02, -3.9959e-02,\n",
       "         1.9205e-02, -7.1998e-02, -4.1827e-02, -2.5947e-02,  6.2555e-03,\n",
       "        -1.6372e-02,  5.1016e-02, -7.1357e-03, -4.0062e-03, -6.4681e-03,\n",
       "        -6.5780e-03, -9.7315e-03, -2.2433e-02,  6.4399e-03, -1.0946e-02,\n",
       "         2.4045e-02, -8.2870e-03, -6.7671e-02,  6.8432e-03,  2.1374e-02,\n",
       "        -4.3389e-02,  2.9914e-02,  1.7118e-02,  1.1233e-02, -2.2943e-02,\n",
       "         3.4587e-03, -3.8132e-03, -4.5638e-03,  7.8295e-03, -3.0783e-02,\n",
       "         2.3075e-02, -1.2495e-02, -1.8919e-02, -2.4893e-02, -1.4982e-02,\n",
       "        -1.0466e-02, -6.6560e-02, -2.4982e-02,  5.7580e-02, -2.8680e-02,\n",
       "         6.1519e-02,  7.7914e-04,  1.8058e-02,  2.3700e-02, -1.2279e-02,\n",
       "        -2.7772e-02, -3.2569e-02,  2.5382e-03, -2.8491e-02, -5.0202e-02,\n",
       "         1.6128e-03, -2.4880e-02, -8.9736e-03, -4.6349e-02, -5.8324e-02,\n",
       "         5.3281e-02, -8.7706e-03,  3.8966e-02, -5.9973e-02, -3.6868e-03,\n",
       "        -2.9777e-02, -5.7926e-02, -7.0362e-02,  1.0042e-02,  6.4579e-02,\n",
       "         2.1224e-03, -2.7929e-02, -2.3738e-01, -1.2784e-02, -4.9344e-03,\n",
       "        -2.2863e-02, -2.8467e-03, -7.9588e-02,  1.3297e-02, -1.2928e-02,\n",
       "        -4.8783e-02, -7.3040e-02, -2.1047e-02, -3.2734e-02,  1.7595e-04,\n",
       "         8.1437e-04,  3.8774e-02, -2.1009e-02, -2.0869e-02, -7.7431e-04,\n",
       "         3.8206e-03,  2.4216e-02, -6.8949e-02, -1.1096e-02, -1.8978e-02,\n",
       "        -2.6904e-02,  2.5016e-02, -1.4139e-02, -7.0601e-02, -4.2752e-02,\n",
       "         2.0510e-02, -2.4979e-02, -4.3413e-02, -1.1243e-02, -9.8995e-03,\n",
       "         2.7080e-02,  1.0732e-02, -5.3788e-03,  1.1744e-02, -6.0511e-02,\n",
       "         2.7970e-02,  3.5857e-03, -2.9556e-02, -1.2063e-02,  2.4685e-02,\n",
       "        -3.3543e-02, -1.3153e-02, -3.9639e-02, -1.4436e-02, -3.1560e-02,\n",
       "        -1.3086e-02, -5.7268e-03,  4.1680e-02, -4.9512e-02,  4.8574e-02,\n",
       "        -8.8746e-02,  5.1145e-03, -6.4500e-03, -1.0259e-02,  2.9276e-02,\n",
       "        -3.1684e-02, -3.9052e-02,  1.0546e-02, -1.8576e-02, -1.9550e-02,\n",
       "        -3.9956e-02, -1.5853e-02, -5.1670e-02, -4.2851e-02,  5.0707e-02,\n",
       "        -6.9387e-02, -1.7567e-04,  2.4100e-02, -2.2542e-02, -4.4441e-02,\n",
       "         1.0864e-02,  7.0277e-02,  6.4145e-03, -2.7230e-02, -2.2657e-02,\n",
       "        -8.0993e-02, -4.6722e-02, -9.7513e-03,  1.6418e-03, -9.0217e-02,\n",
       "        -1.2232e-02, -3.1899e-02, -4.8909e-02, -3.6300e-02, -1.4735e-02,\n",
       "        -3.2202e-02,  7.6208e-03,  2.1645e-02, -4.4748e-03,  2.1284e-02,\n",
       "        -3.2909e-02, -8.9621e-03, -3.6492e-02,  2.8094e-02, -4.9395e-02,\n",
       "        -3.4617e-02, -4.0033e-02, -1.7475e-02, -6.1422e-02, -2.7156e-02,\n",
       "        -4.1687e-02,  2.9331e-03, -9.4555e-03,  1.1271e-02,  8.9175e-02,\n",
       "        -6.9751e-02,  2.5904e-02,  2.6297e-04,  1.2308e-03, -2.2504e-03,\n",
       "        -5.0318e-02, -3.0887e-02,  1.0029e-02,  1.3946e-02, -1.8923e-02,\n",
       "        -1.7352e-02, -2.7849e-02, -3.5050e-02, -1.7475e-03, -3.7229e-02,\n",
       "        -3.0784e-02, -3.1290e-03,  1.2695e-02,  1.4338e-03, -2.2671e-02,\n",
       "        -3.4279e-02, -1.2967e-02,  1.5544e-02, -2.8814e-02, -1.7790e-02,\n",
       "        -6.5507e-02, -5.2084e-02, -7.2753e-03, -6.7256e-02, -4.9762e-02,\n",
       "        -2.7061e-02,  3.7310e-03, -2.1767e-02, -7.1013e-02, -2.7204e-03,\n",
       "        -7.6133e-03, -2.0863e-02, -6.3412e-03, -6.0435e-03, -8.7311e-02,\n",
       "        -6.9254e-02, -2.9839e-02, -4.2251e-02, -4.6714e-02, -4.9754e-02,\n",
       "        -2.7383e-02,  2.7360e-02, -1.1769e-02, -4.7239e-03,  2.5341e-02,\n",
       "         2.3355e-03, -4.8538e-02,  6.0749e-03, -2.8723e-02,  2.2636e-02,\n",
       "        -1.8672e-02,  1.8416e-02, -2.2311e-02,  1.4115e-02,  6.8744e-02,\n",
       "        -1.9231e-03, -2.3426e-02, -4.1642e-02,  7.7535e-03,  1.6197e-02,\n",
       "         5.4071e-02,  4.5781e-03, -2.0455e-03, -8.3638e-02, -4.3152e-02,\n",
       "        -3.7687e-02, -1.1952e-01, -3.5734e-02, -1.6372e-02, -4.6566e-02,\n",
       "        -4.9267e-03, -8.3236e-03,  3.0028e-02,  8.4912e-02, -3.0771e-02,\n",
       "        -3.6750e-02, -2.1298e-02, -3.3578e-03, -2.4656e-02,  2.1881e-02,\n",
       "        -3.0009e-02,  3.9030e-02, -5.1275e-02, -1.2669e-02,  3.3849e-03,\n",
       "        -2.7313e-02, -1.5823e-03, -2.6419e-03, -5.9865e-02,  8.1448e-03,\n",
       "        -4.8694e-02,  3.5925e-02, -6.7909e-04, -1.2019e-02, -3.2882e-02,\n",
       "        -1.0579e-02, -6.7117e-02,  2.8345e-02,  1.5547e-02,  5.7351e-02,\n",
       "        -2.9748e-02, -1.1511e-02,  2.9312e-02, -1.0290e-03, -2.4354e-02,\n",
       "        -5.8069e-03, -5.8718e-02,  5.8955e-02, -3.2610e-03, -2.4550e-02,\n",
       "        -5.9614e-02, -1.8021e-03,  2.4396e-02,  2.8734e-02,  1.8024e-02,\n",
       "         1.5305e-02,  2.7121e-02, -5.4986e-02, -4.4349e-02, -1.6460e-03,\n",
       "         4.2693e-02, -3.6395e-02,  1.5699e-02, -5.8932e-02,  3.1849e-02,\n",
       "        -7.9730e-03, -3.9630e-02,  1.0729e-02,  3.5676e-02, -2.4115e-02,\n",
       "         2.6541e-02, -2.2230e-02,  4.5944e-03, -2.0942e-02, -8.7534e-04,\n",
       "         3.0552e-02, -2.9945e-02, -1.4035e-02, -3.4716e-04,  8.0571e-03,\n",
       "        -4.6626e-02,  1.1523e-02, -1.3744e-02], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertimbau_embeddings(max(processed_new_tokenizer['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676a3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertimbau_embeddings(processed_new_tokenizer['input_ids']).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e5aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('return_dict', True, True)  -- ('output_hidden_states', False, False)  -- ('output_attentions', False, False)  -- ('torchscript', False, False)  -- ('torch_dtype', None, None)  -- ('use_bfloat16', False, False)  -- ('tf_legacy_loss', False, False)  -- ('pruned_heads', {}, {})  -- ('tie_word_embeddings', True, True)  -- ('chunk_size_feed_forward', 0, 0)  -- ('is_encoder_decoder', False, False)  -- ('is_decoder', False, False)  -- ('cross_attention_hidden_size', None, None)  -- ('add_cross_attention', False, False)  -- ('tie_encoder_decoder', False, False)  -- ('max_length', 20, 20)  -- ('min_length', 0, 0)  -- ('do_sample', False, False)  -- ('early_stopping', False, False)  -- ('num_beams', 1, 1)  -- ('num_beam_groups', 1, 1)  -- ('diversity_penalty', 0.0, 0.0)  -- ('temperature', 1.0, 1.0)  -- ('top_k', 50, 50)  -- ('top_p', 1.0, 1.0)  -- ('typical_p', 1.0, 1.0)  -- ('repetition_penalty', 1.0, 1.0)  -- ('length_penalty', 1.0, 1.0)  -- ('no_repeat_ngram_size', 0, 0)  -- ('encoder_no_repeat_ngram_size', 0, 0)  -- ('bad_words_ids', None, None)  -- ('num_return_sequences', 1, 1)  -- ('output_scores', False, False)  -- ('return_dict_in_generate', False, False)  -- ('forced_bos_token_id', None, None)  -- ('forced_eos_token_id', None, None)  -- ('remove_invalid_values', False, False)  -- ('exponential_decay_length_penalty', None, None)  -- ('suppress_tokens', None, None)  -- ('begin_suppress_tokens', None, None)  -- ('architectures', ['BertForMaskedLM'], None)  -- ('finetuning_task', None, None)  -- ('id2label', {0: 'LABEL_0', 1: 'LABEL_1'}, {0: 'LABEL_0', 1: 'LABEL_1'})  -- ('label2id', {'LABEL_0': 0, 'LABEL_1': 1}, {'LABEL_0': 0, 'LABEL_1': 1})  -- ('tokenizer_class', None, None)  -- ('prefix', None, None)  -- ('bos_token_id', None, 0)  -- ('pad_token_id', 0, 1)  -- ('eos_token_id', None, 2)  -- ('sep_token_id', None, None)  -- ('decoder_start_token_id', None, None)  -- ('task_specific_params', None, None)  -- ('problem_type', None, None)  -- ('_name_or_path', '/home/luckagianvechio/Documents/Material Estudo TCC/code/bertimbau', '')  -- ('_commit_hash', None, None)  -- ('_attn_implementation_internal', None, None)  -- ('transformers_version', None, None)  -- ('vocab_size', 29794, 50265)  -- ('hidden_size', 768, 768)  -- ('num_hidden_layers', 12, 12)  -- ('num_attention_heads', 12, 12)  -- ('intermediate_size', 3072, 3072)  -- ('hidden_act', 'gelu', 'gelu')  -- ('hidden_dropout_prob', 0.1, 0.1)  -- ('attention_probs_dropout_prob', 0.1, 0.1)  -- ('max_position_embeddings', 512, 512)  -- ('type_vocab_size', 2, 2)  -- ('initializer_range', 0.02, 0.02)  -- ('layer_norm_eps', 1e-12, 1e-05)  -- ('classifier_dropout', None, None)  -- "
     ]
    }
   ],
   "source": [
    "for key in model.config.__dict__.keys():\n",
    "    try:\n",
    "        print((key, bertimbau_model.config.__dict__[key], model.config.__dict__[key]), end = \"  -- \")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85353e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('all': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac26dd6dfbaca8db3a81442d3498aaba3accde3927255076a0ada8b4751f69b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
