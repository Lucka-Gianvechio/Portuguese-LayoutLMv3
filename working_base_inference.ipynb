{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckagianvechio/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3Config, LayoutLMv3Model\n",
    "import json\n",
    "\n",
    "# Initializing a LayoutLMv3 microsoft/layoutlmv3-base style configuration\n",
    "with open(\"/home/luckagianvechio/Documents/Material Estudo TCC/code/layoutlmv3/config.json\", \"r\") as jeiso:\n",
    "    configuration = LayoutLMv3Config(**json.load(jeiso))\n",
    "\n",
    "# Initializing a model (with random weights) from the microsoft/layoutlmv3-base style configuration\n",
    "model = LayoutLMv3Model(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ImageProcessor\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
    "image_processor = LayoutLMv3ImageProcessor.from_pretrained(\"microsoft/layoutlmv3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckagianvechio/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/models/layoutlmv3/processing_layoutlmv3.py:195: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3Processor\n",
    "\n",
    "lmv3_processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "lmv3_processor.feature_extractor.apply_ocr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import listdir\n",
    "\n",
    "main_path = Path(\"/home/luckagianvechio/Documents/Material Estudo TCC/IIT CDIP/images.a.a/imagesa/a/a\")\n",
    "a_path = Path(\"a/\")\n",
    "a_img_folder_path = [main_path / a_path / Path(pt) for pt in listdir(main_path / a_path)]\n",
    "a_img_path = []\n",
    "for pt in a_img_folder_path:\n",
    "    files = listdir(pt)\n",
    "    for file in files:\n",
    "        if not file.split(\".\")[1] == \"xml\":\n",
    "            a_img_path.append(pt / file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr_tools import get_ocr_word_box_list, preprocess_image, resize_image, read_image, normalize_bbox\n",
    "\n",
    "image = read_image(a_img_path[0])\n",
    "text_boxes, shape = get_ocr_word_box_list(a_img_path[0])\n",
    "words = [k[\"text\"] for k in text_boxes]\n",
    "boxes = [normalize_bbox(k[\"bbox\"], shape[0], shape[1]) for k in text_boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = lmv3_processor(\n",
    "    image,\n",
    "    words,\n",
    "    boxes=boxes,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3TextEmbeddings(\n",
      "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "  (token_type_embeddings): Embedding(1, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "  (x_position_embeddings): Embedding(1024, 128)\n",
      "  (y_position_embeddings): Embedding(1024, 128)\n",
      "  (h_position_embeddings): Embedding(1024, 128)\n",
      "  (w_position_embeddings): Embedding(1024, 128)\n",
      ") tensor([[    0,  7330, 15318,   109,   242,  2841,  1046,    17,    27,   262,\n",
      "         24303, 37317,     4,  4979, 13895,   565, 14718, 10566,    35,   719,\n",
      "           753,     6,  7528, 33355, 10566,    35,  5457,   759,   733,     6,\n",
      "          7528, 40950,  1499,  4177, 10486,    35, 30627,     6,   886, 40950,\n",
      "          1499, 11185,   337,  1872,    44,   711,   713, 11020, 20026, 13133,\n",
      "             9,   143,  1203,     6, 11566,     6, 15155,  1120,    50, 11267,\n",
      "          2332,    14, 26238,  5504, 14407,    50, 22589, 14281,    11,    10,\n",
      "          3271,  7097,  2259,     4,  1909,   352,  7097,     7, 41684,  1171,\n",
      "          6185, 30792,     6,  2380,     9,  3413,     8,  7619,   990, 20515,\n",
      "          1203, 15659,     4,    20, 11020, 30540,  8127,  1480,  7205,   975,\n",
      "             7,     5,   511,    35,  2055, 26855,  1025,     5, 11457,    14,\n",
      "            32, 10059,     7,  1331, 14407,     4, 11548,  9501,  1734,   341,\n",
      "             7,  4240, 14407, 11548, 25675,    29,    41, 10718, 14450,    83,\n",
      "           922, 13562,  5846,  1734,  5505,  7258, 26855,    15,  1038, 12142,\n",
      "             7,    41, 22233,  6418,  2055, 40989,  9390,   137,     5,  2375,\n",
      "          1248,     9,    42, 22474, 39877,    50,     7,   143, 14573,  1385,\n",
      "             9,    41,  2210,  1355, 38906, 43650,     8,  1076,   876,  5410,\n",
      "           328, 20170,  3553,   337,   122,  5152,     8,    32,  9986,    30,\n",
      "            42, 11020,   531,    28,  2928,   624,   132,   107,     9,     5,\n",
      "          2375,  1248,     9,     5, 11020,    36, 21206,   733,     6,  6193,\n",
      "           322,   885,   290,   290,  1021,    10,   787,   234,  1021,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckagianvechio/Documents/Material Estudo TCC/code/all/lib/python3.9/site-packages/transformers/modeling_utils.py:993: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.2020, -1.0938, -0.1600,  ...,  1.3920,  0.7154,  0.8923],\n",
       "         [ 0.9497,  0.1321, -1.1830,  ..., -0.3233, -0.1729,  1.4400],\n",
       "         [ 1.1455,  1.7027, -1.3415,  ...,  0.9101,  0.1392, -0.0035],\n",
       "         ...,\n",
       "         [ 0.9331, -0.2009, -0.5256,  ...,  0.4081,  0.5432,  0.5877],\n",
       "         [ 0.5243, -0.5275, -0.1765,  ..., -0.9974,  0.4886,  0.8465],\n",
       "         [ 0.4995, -0.8935,  0.4980,  ..., -0.0478,  0.8550,  0.7672]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Config, LayoutLMv3Model\n",
    "import json\n",
    "\n",
    "# Initializing a LayoutLMv3 microsoft/layoutlmv3-base style configuration\n",
    "with open(\"/home/luckagianvechio/Documents/Material Estudo TCC/code/layoutlmv3/config_alterations.json\", \"r\") as jeiso:\n",
    "    configuration = LayoutLMv3Config(**json.load(jeiso))\n",
    "\n",
    "# Initializing a model (with random weights) from the microsoft/layoutlmv3-base style configuration\n",
    "model = LayoutLMv3Model(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel  # or BertModel, for BERT without pretraining heads\n",
    "\n",
    "bertimbau_model = BertModel.from_pretrained('/home/luckagianvechio/Documents/Material Estudo TCC/code/bertimbau')\n",
    "\n",
    "model.embeddings.word_embeddings = bertimbau_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_processor import tokenize_with_bbox, pad_tokenized\n",
    "\n",
    "new_processed = tokenize_with_bbox(\n",
    "    words=words,\n",
    "    bboxs=boxes,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "padded_new_processed = pad_tokenized(new_processed, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "processed_new_tokenizer = processed.copy()\n",
    "processed_new_tokenizer[\"input_ids\"][0] = Tensor(padded_new_processed[\"input_ids\"])\n",
    "processed_new_tokenizer[\"bbox\"][0] = Tensor(padded_new_processed[\"bbox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3TextEmbeddings(\n",
      "  (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (position_embeddings): Embedding(512, 768, padding_idx=0)\n",
      "  (x_position_embeddings): Embedding(1024, 128)\n",
      "  (y_position_embeddings): Embedding(1024, 128)\n",
      "  (h_position_embeddings): Embedding(1024, 128)\n",
      "  (w_position_embeddings): Embedding(1024, 128)\n",
      ") tensor([[  476,  2097,  5131,   171, 22279,   173,  9174, 22361,   977,   197,\n",
      "         19647,   119,   257, 22309,   192, 20257,  1043, 22282, 22286,  1292,\n",
      "           185,   131,  4534,   210,   604,   275,   117,  6827,   192, 14782,\n",
      "          5965,  1086,  1292,   185,   131,   134,  4424,   210,   604,  2250,\n",
      "           117,  6827,  4151,  9581,  1131,  1992,  4009,  9558,   131,  2174,\n",
      "           897,   117, 19921,  4151,  9581,  1131,   540,   477,  1355,  8586,\n",
      "         16989,  4189,   387,  1710,   258,  4095,  5257, 22281,  1269,  2812,\n",
      "           265,   586,   360, 22326,  1493,   117, 13608,   140,   117,  9109,\n",
      "         22284,   438,   416,  1814,   156,  4267, 12893, 12230,   352, 11760,\n",
      "          4530,   143, 14883,   823,  6060, 22281,   438, 15460, 15203,   156,\n",
      "          5294,  5042,  4119,   238,   123,  1336,  2021,  1003, 20900,   817,\n",
      "           352,   484,   119, 10927,  2021,  1003, 20900,  7384,  1131,   868,\n",
      "          1111,   291, 22286,   243,   141,  3425, 22290,  4201, 22281,   117,\n",
      "           898,  1111,   586, 10187,  6845,  4403,  1961,   958,  1009, 10773,\n",
      "           833,  1493,  4201, 22281,   119,  1389,  4189,   387,  1710, 15040,\n",
      "          3341, 20660, 22321, 12127, 22310, 22327, 22350,   374,  1621,  3370,\n",
      "          7127,   446,   131,   116, 13463,   255,   601,   878,  1621, 11050,\n",
      "          1932, 12230,   352, 12346,  4073,  1451, 22284,   374, 13970, 22290,\n",
      "         14883,   823,  6060, 22281,   119,   208,   761,   580,   550,   873,\n",
      "          4095, 20929,   727,   430,   374,  4636, 22286, 14883,   823,  6060,\n",
      "         22281,   208, 13463,   255,   360, 15509,  4175, 22285,  4339,   284,\n",
      "          2116, 22290,   914,  6417,   873,  4095, 20929,   100, 13463,   255,\n",
      "          3185,  2671, 20057, 22326, 12756,  2853,   374,   360,   558,  8849,\n",
      "           185,  4163,  2719,  4473,   116, 10389,  5965, 22281,  2246,  3640,\n",
      "          5294,   512, 22279,  1621,  1691, 18273,  6758,   180,   185,   586,\n",
      "         12230,   145,  4189, 20313,   289,   438,   374,   360, 22326,  5302,\n",
      "         22279,  7761,   370, 22287,   586,   360, 21877,   833,   598,  5965,\n",
      "           187,   945, 15738, 22279,  1961, 15460,   268,   106, 11760,  4530,\n",
      "           210,   265, 22281, 12230,   162,   202, 22343,  7288,  1961, 12346,\n",
      "           258,  4095,  5257,   430, 11100, 12230,   145,  4189,   387,  1710,\n",
      "          3270, 22286,  5294,  2873, 20384, 10125,   147,   245,  4759, 22279,\n",
      "          6425,   586,  1621,  1691, 18273,  6758,   180,   185,   586,  1621,\n",
      "          4189,   387,  1710,   113,  4424,   210,   604,  2250,   117,  6051,\n",
      "           114,   119,  2702,  1015,  1015,   146,   123,   137,   248,   146,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 1.6519,  1.2543,  0.0391,  ...,  0.8546,  0.1847,  0.5731],\n",
       "         [ 1.0682, -0.2072,  0.6367,  ...,  0.0131,  0.8519,  0.4590],\n",
       "         [ 0.7802,  1.2017, -0.1197,  ...,  0.1721, -0.2817,  2.4566],\n",
       "         ...,\n",
       "         [ 0.0327, -0.4726, -0.4509,  ...,  0.3562,  0.6582,  0.8056],\n",
       "         [ 1.3668,  0.3628, -0.2070,  ...,  0.2546, -0.2959,  1.2254],\n",
       "         [ 0.9313, -0.3510,  0.0607,  ...,  0.5033,  0.2006,  0.9044]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**processed_new_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('all': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac26dd6dfbaca8db3a81442d3498aaba3accde3927255076a0ada8b4751f69b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
